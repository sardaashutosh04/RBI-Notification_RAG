{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sardaashutosh04/sarvam-ai-assignment/blob/main/SarvamAI_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SFRFc1J0d3qV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5429e138-6655-4035-913e-ffbd0d02ef4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for neo4j (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip3 install langchain-community neo4j langchain langchain-openai --quiet #beautifulsoup4 PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc1TqRNoX1LI"
      },
      "source": [
        "## Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import json\n",
        "\n",
        "import requests\n",
        "import pickle\n",
        "from PyPDF2 import PdfReader\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "wwfN5vRH1rNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y0TgEpyR3PL"
      },
      "outputs": [],
      "source": [
        "data = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POsZXlXXEQ1G"
      },
      "outputs": [],
      "source": [
        "with open('/content/rbi_notification_toc_2023_1991_20230930_212821.json', 'rb') as f:\n",
        "    data = json.load(f)\n",
        "os.mkdir('/content/data')\n",
        "for y, c in data.items():\n",
        "    with open(f'/content/data/{y}.html', 'w') as f:\n",
        "        f.write(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZMkK9PWJBgf"
      },
      "outputs": [],
      "source": [
        "def is_date(date):\n",
        "    valid_months_short = ['Jan', 'Feb', 'Mar', 'Apr',\n",
        "                          'May', 'Jun', 'Jul', 'Aug',\n",
        "                          'Sep', 'Oct', 'Nov', 'Dec']\n",
        "    valid_months_long = ['January', 'Febuary', 'March', 'April',\n",
        "                         'May', 'June', 'July', 'August',\n",
        "                         'September', 'October', 'November', 'December']\n",
        "    date = date.strip()\n",
        "\n",
        "    try:\n",
        "        date, year = date.split(',')\n",
        "        if int(year) < 1991 or int(year) > 2023:\n",
        "            return False\n",
        "\n",
        "        mon, date = date.split(' ')\n",
        "        if mon not in valid_months_short:\n",
        "            if mon not in valid_months_long:\n",
        "                return False\n",
        "\n",
        "        if int(date) > 31 or int(date) < 1:\n",
        "            return False\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RY-gU6Gw0aJ8"
      },
      "outputs": [],
      "source": [
        "def extract_from_pdf(pdf_url):\n",
        "    if pdf_url is None:\n",
        "        return ''\n",
        "    if not pdf_url.startswith('https://rbidocs.rbi.org.in'):\n",
        "        if pdf_url:\n",
        "            print(f'Incorrect URL: {pdf_url}')\n",
        "        return ''\n",
        "    r = requests.get(pdf_url)\n",
        "    f = io.BytesIO(r.content)\n",
        "\n",
        "    reader = PdfReader(f)\n",
        "    info = ''\n",
        "    for page in range(len(reader.pages)):\n",
        "        info += reader.pages[page].extract_text()\n",
        "    return info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlieTDZNF48L"
      },
      "outputs": [],
      "source": [
        "def extract_notification_from_table(table):\n",
        "    try:\n",
        "        pdf_url = table.find('a')['href']\n",
        "    except:\n",
        "        pdf_url = ''\n",
        "\n",
        "    try:\n",
        "        title = table.find('b').text\n",
        "    except:\n",
        "        title = ''\n",
        "\n",
        "    date_flag = False\n",
        "    info = ''\n",
        "    date = ''\n",
        "    for p in table.findAll('p'):\n",
        "        if not date_flag:\n",
        "            if is_date(p.text):\n",
        "                date = p.text\n",
        "    try:\n",
        "        info = extract_from_pdf(pdf_url)\n",
        "    except Exception as e:\n",
        "        print(f'ERROR: extracting info from {pdf_url} failed due to exception {e}. \\nNotification: {title}')\n",
        "\n",
        "    notification = {\n",
        "        'title': title,\n",
        "        'date': date,\n",
        "        'info': info,\n",
        "        'source': pdf_url\n",
        "    }\n",
        "    return notification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pAXX9blJ_lg"
      },
      "outputs": [],
      "source": [
        "done_files = ['1991.html', '1992.html', '1993.html', '1994.html', '1995.html', '1996.html',\n",
        "              '1997.html', '1998.html', '1999.html', '2000.html', '2001.html', '2002.html',\n",
        "              '2003.html', '2004.html', '2005.html', '2006.html', '2007.html', '2008.html',\n",
        "              '2009.html', '2010.html', '2011.html', '2012.html', '2013.html', '2014.html',\n",
        "              '2015.html', '2016.html', '2017.html', '2018.html', '2019.html', '2020.html',\n",
        "              '2021.html', '2022.html', '2023.html']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR_tlwZ1FYeP"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "directory = '/content/data'\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.html') and filename not in done_files:\n",
        "        print(f'Extracting info from {filename}...')\n",
        "        notifications = []\n",
        "        HTMLFileToBeOpened = open(os.path.join(directory, filename), \"r\")\n",
        "        contents = HTMLFileToBeOpened.read()\n",
        "        beautifulSoupText = BeautifulSoup(contents, 'html.parser')\n",
        "        date = None\n",
        "        contents = beautifulSoupText.find('tbody').contents\n",
        "        for content in contents:\n",
        "            if content.find('b'):\n",
        "                if is_date(content.find('b').text):\n",
        "                    date = content.find('b').text\n",
        "                    continue\n",
        "                else:\n",
        "                    continue\n",
        "            elif content.findAll('a'):\n",
        "                for c in content.findAll('a'):\n",
        "                    title = None\n",
        "                    info = None\n",
        "                    pdf_url = None\n",
        "                    if c.text:\n",
        "                        title = c.text\n",
        "                    else:\n",
        "                        pdf_url = c['href']\n",
        "                        try:\n",
        "                            info = extract_from_pdf(pdf_url)\n",
        "                        except Exception as e:\n",
        "                            print(f'ERROR: extracting info from {pdf_url} failed due to exception {e}. \\nNotification: {title}')\n",
        "                            info = ''\n",
        "                notifications.append({\n",
        "                    'title': title,\n",
        "                    'date': date,\n",
        "                    'info': info,\n",
        "                    'source': pdf_url\n",
        "                })\n",
        "        output_filename = f'/content/rbi_notifications_{filename.split(\".\")[0]}_with_info.json'\n",
        "        with open(output_filename, 'w') as f:\n",
        "            json.dump(notifications, f)\n",
        "        # files.download(output_filename)\n",
        "        print(f'Extraction of notifications from file {filename} complete!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtKx3p9PkWlG"
      },
      "outputs": [],
      "source": [
        "with open('/content/filenames_notification_not_in_toc.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "data = data[0]\n",
        "notifications = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLLcCQwhOnlH"
      },
      "outputs": [],
      "source": [
        "i = 1 + 5000 + 1000 + 1000 + 1000 + 1000\n",
        "for url in list(data.keys())[i-1:]:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        contents = response.content\n",
        "        beautifulSoupText = BeautifulSoup(contents, 'html.parser')\n",
        "        table = beautifulSoupText.find('table')\n",
        "        notifications.append(extract_notification_from_table(table))\n",
        "    except Exception as e:\n",
        "        print(f'ERROR: extracting info from {url} failed due to exception {e}.')\n",
        "        continue\n",
        "\n",
        "    if i%1000 == 0:\n",
        "        print(f\"{i-999}-{i} notifications fetched!\")\n",
        "        output_filename = f'/content/rbi_notifications_not_in_toc_{i-999}_{i}_with_info.json'\n",
        "        with open(output_filename, 'w') as f:\n",
        "            json.dump(notifications, f)\n",
        "            notifications = []\n",
        "    i += 1\n",
        "\n",
        "output_filename = '/content/rbi_notifications_not_in_toc_10001_10566_with_info.json'\n",
        "with open(output_filename, 'w') as f:\n",
        "    json.dump(notifications, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TBXBU-KYFM6"
      },
      "source": [
        "## Creating Knowledge Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EIC-uNUnJC0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28bece6-1676-44da-a3a7-cd4935e6897d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_core.embeddings import Embeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "import textwrap\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3yUnb7I-Xidz"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/SarvamAi-RAG/userdata.json', 'r') as f:\n",
        "    userdata = json.load(f)\n",
        "\n",
        "NEO4J_URI = userdata.get('NEO4J_URI')\n",
        "NEO4J_USERNAME = userdata.get('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = userdata.get('NEO4J_PASSWORD')\n",
        "NEO4J_DB = 'neo4j'\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# Global constants\n",
        "VECTOR_INDEX_NAME = 'notification_chunks'\n",
        "VECTOR_NODE_LABEL = 'Chunk'\n",
        "VECTOR_SOURCE_PROPERTY = 'text'\n",
        "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DB\n",
        ")"
      ],
      "metadata": {
        "id": "OO5Y6lVI53EG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Nodes"
      ],
      "metadata": {
        "id": "-1aMVsKxjnKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")\n",
        "\n",
        "\n",
        "def split_notifications_data_from_file(notification):\n",
        "    chunks_with_metadata = []\n",
        "    item_text = notification['info']\n",
        "    if item_text is None:\n",
        "        item_text = ''\n",
        "    item_text_chunks = text_splitter.split_text(item_text)\n",
        "    chunk_seq_id = 0\n",
        "    title = notification['title']\n",
        "    date = notification['date']\n",
        "    source = notification['source']\n",
        "    for chunk in item_text_chunks:\n",
        "        # finally, construct a record with metadata and the chunk text\n",
        "        chunks_with_metadata.append({\n",
        "            'text': chunk,\n",
        "            'chunkSeqId': chunk_seq_id,\n",
        "            # constructed metadata...\n",
        "            'chunkId': f'{title}-chunk{chunk_seq_id:04d}',\n",
        "            # metadata from file...\n",
        "            'title': title,\n",
        "            'date': date,\n",
        "            'source': source,\n",
        "        })\n",
        "        chunk_seq_id += 1\n",
        "    return chunks_with_metadata"
      ],
      "metadata": {
        "id": "RnzYfNhg2tSS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_chunk_node_query = \"\"\"\n",
        "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
        "    ON CREATE SET\n",
        "        mergedChunk.title = $chunkParam.title,\n",
        "        mergedChunk.date = $chunkParam.date,\n",
        "        mergedChunk.source = $chunkParam.source,\n",
        "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId,\n",
        "        mergedChunk.text = $chunkParam.text\n",
        "RETURN mergedChunk\n",
        "\"\"\"\n",
        "\n",
        "distinct_chunk_constraint_query = \"\"\"\n",
        "CREATE CONSTRAINT unique_chunk IF NOT EXISTS\n",
        "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
        "\"\"\"\n",
        "\n",
        "create_vector_index_query = f\"\"\"\n",
        "         CREATE VECTOR INDEX `{VECTOR_INDEX_NAME}` IF NOT EXISTS\n",
        "          FOR (c:Chunk) ON (c.textEmbedding)\n",
        "          OPTIONS {{ indexConfig: {{\n",
        "            `vector.dimensions`: 512,\n",
        "            `vector.similarity_function`: 'cosine'\n",
        "         }}}}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YhOAcghk98pD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done_files = ['rbi_notifications_2008_with_info.json', 'rbi_notifications_2000_with_info.json',\n",
        "              'rbi_notifications_2015_with_info.json', 'rbi_notifications_2012_with_info.json',\n",
        "              'rbi_notifications_2007_with_info.json', 'rbi_notifications_1991_with_info.json',\n",
        "              'rbi_notifications_1992_with_info.json', 'rbi_notifications_1999_with_info.json',\n",
        "              'rbi_notifications_1995_with_info.json', 'rbi_notifications_1998_with_info.json',\n",
        "              'rbi_notifications_1994_with_info.json', 'rbi_notifications_2022_with_info.json',\n",
        "              'rbi_notifications_2023_with_info.json', 'rbi_notifications_1993_with_info.json',\n",
        "              'rbi_notifications_2014_with_info.json', 'rbi_notifications_2021_with_info.json',\n",
        "              'rbi_notifications_1997_with_info.json', 'rbi_notifications_1996_with_info.json',\n",
        "              'rbi_notifications_2020_with_info.json', 'rbi_notifications_2009_with_info.json',\n",
        "              'rbi_notifications_2001_with_info.json', 'rbi_notifications_2017_with_info.json',\n",
        "              'rbi_notifications_2010_with_info.json', 'rbi_notifications_2016_with_info.json',\n",
        "              'rbi_notifications_2019_with_info.json', 'rbi_notifications_2003_with_info.json',\n",
        "              'rbi_notifications_2004_with_info.json', 'rbi_notifications_2011_with_info.json',\n",
        "              'rbi_notifications_2002_with_info.json', 'rbi_notifications_2005_with_info.json',\n",
        "              'rbi_notifications_2006_with_info.json', 'rbi_notifications_2013_with_info.json',\n",
        "              'rbi_notifications_2018_with_info.json', 'rbi_notifications_not_in_toc_1_1000_with_info.json',\n",
        "              'rbi_notifications_not_in_toc_3001_4000_with_info.json', 'rbi_notifications_not_in_toc_1001_2000_with_info.json',\n",
        "              'rbi_notifications_not_in_toc_2001_3000_with_info.json', 'rbi_notifications_not_in_toc_8001_9000_with_info.json',\n",
        "              'rbi_notifications_not_in_toc_4001_5000_with_info.json', 'rbi_notifications_not_in_toc_5001_6000_with_info.json',\n",
        "              'rbi_notifications_not_in_toc_6001_7000_with_info.json', 'rbi_notifications_not_in_toc_7001_8000_with_info.json',\n",
        "              'rbi_notifications_not_in_toc_9001_10000_with_info.json', 'rbi_notifications_not_in_toc_10001_10566_with_info.json']"
      ],
      "metadata": {
        "id": "Sav0gpu5Bs3Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/SarvamAi-RAG/data'"
      ],
      "metadata": {
        "id": "KoQ7Njgij_xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for notifications_file in os.listdir(DATA_PATH):\n",
        "    if notifications_file not in done_files:\n",
        "        with open(os.path.join(DATA_PATH, notifications_file), 'r') as f:\n",
        "            notifications = json.load(f)\n",
        "\n",
        "        kg.query(distinct_chunk_constraint_query)\n",
        "        for notification in notifications:\n",
        "            notification_chunks = split_notifications_data_from_file(notification)\n",
        "            for chunk in notification_chunks:\n",
        "                kg.query(merge_chunk_node_query,\n",
        "                params={\n",
        "                    'chunkParam': chunk\n",
        "                })\n",
        "        print(f'Chunk Nodes added to knowledge graph from file {notifications_file}')"
      ],
      "metadata": {
        "id": "YLt3IYzv4cm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(create_vector_index_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmuzydlxK5g5",
        "outputId": "343f2135-51f0-4233-9665-dbaa51b39994"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "id": "Q7rUroPGAJ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Embedding"
      ],
      "metadata": {
        "id": "A6YIL18qjwBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTensorflowHubEmbeddings(Embeddings):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        if texts:\n",
        "            embeddings = []\n",
        "            for embedding in self.model(texts):\n",
        "                embeddings.append(embedding.numpy())\n",
        "            return embeddings\n",
        "        else:\n",
        "            return [[]]\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        return self.model([text])[0].numpy()\n",
        "\n",
        "embeddings_model = CustomTensorflowHubEmbeddings()"
      ],
      "metadata": {
        "id": "gB2yvmYiD5UD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_nodes = kg.query(\"\"\"\n",
        "    MATCH (chunk: Chunk) WHERE chunk.textEmbedding IS NULL\n",
        "    RETURN chunk.chunkId, chunk.text\"\"\")\n",
        "\n",
        "create_text_embeddings_query = \"\"\"\n",
        "    MATCH (chunk:Chunk) WHERE chunk.chunkId = $id\n",
        "    WITH chunk, $embedding AS vector\n",
        "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
        "    \"\"\"\n",
        "\n",
        "for chunk in chunk_nodes:\n",
        "    kg.query(create_text_embeddings_query,\n",
        "             params={'id': chunk['chunk.chunkId'],\n",
        "                     'embedding': embeddings_model.embed_query(chunk['chunk.text'])})"
      ],
      "metadata": {
        "id": "CWxwcDhfGzAj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (chunk: Chunk) WHERE chunk.textEmbedding IS NULL\n",
        "    RETURN count(chunk)\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uV_CFKQmlds",
        "outputId": "cc7fcd01-3b1f-42a3-a71a-7843f08dbbf8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'count(chunk)': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(kg.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30FF316YuTRA",
        "outputId": "7585763f-7769-4bb7-858b-55da4cd9ca26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties are the following:\n",
            "Chunk {chunkId: STRING, title: STRING, date: STRING, source: STRING, chunkSeqId: INTEGER, text: STRING, textEmbedding: LIST}\n",
            "Relationship properties are the following:\n",
            "\n",
            "The relationships are the following:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query Similarity Search"
      ],
      "metadata": {
        "id": "9jgxKeNvwRb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neo4j_vector_search(question):\n",
        "    \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
        "    question_embedding = embeddings_model.embed_query(question)\n",
        "\n",
        "    vector_search_query = \"\"\"\n",
        "    WITH $question_embedding AS question_vector\n",
        "    CALL db.index.vector.queryNodes($index_name, $top_k, question_vector) yield node, score\n",
        "    RETURN score, node.title as title, node.date as date, node.text AS text\n",
        "    \"\"\"\n",
        "    similar = kg.query(vector_search_query,\n",
        "                        params={\n",
        "                        'question_embedding': question_embedding,\n",
        "                        'index_name':VECTOR_INDEX_NAME,\n",
        "                        'top_k': 10})\n",
        "    return similar"
      ],
      "metadata": {
        "id": "QU1EH6SCvo3L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neo4j_vector_search(\"Policy changes in 2000?\")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMaVH5ivwxXh",
        "outputId": "3892e147-0cb2-4b93-db12-51ca4df31dd1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6575847864151001,\n",
              " 'title': 'Foreign Exchange Management (Borrowing or Lending in Foreign Exchange) (Amendment) Regulations, 2000',\n",
              " 'date': '',\n",
              " 'text': 'Foreign Exchange Management (Borrowing or Lending in Foreign Exchange) \\n(Amendment) Regulations, 2000 \\n \\nReserve Bank of India \\n(Exchange Control Department) \\nCentral Office \\nMumbai 400 001 \\n Notification No.FEMA 26 /2000-RB \\ndated 14\\nth August, 2000 \\n Foreign Exchange Management (Borrowing or Lending in Foreign Exchange) (Amendment) Regulations, 2000 \\n \\n In exercise of the powers c onferred by clause (d) of sub-se ction (3) of section 6, and sub-\\nsection (2) of Section 47 of the Forei gn Exchange Management Act, 1999 (42 of 1999), and in \\npartial modification of its notif ication No.FEMA 3/2000-RB dated 3\\nrd May 2000, the Reserve Bank \\nof India makes the following Regulations  to amend the Foreign Exchange Management \\n(Borrowing or Lending in Foreign Exchange) Regulations 2000, namely :- \\n \\n2. Short title and commencement:- \\n \\n(i) These Regulations may be called the Foreign Exchange Management (Borrowing or \\nLending in Foreign Exchange) (Amendment) Regulations, 2000.  \\n \\n(ii) They shall come into force with immediate effect. \\n \\n3. Amendment of the Regulations \\n \\nIn the Foreign Exchange Management (Bo rrowing or Lending in Foreign Exchange) \\nRegulations 2000, in Regulation 4, in sub-regulati on (I), in clause (iv), the words “EEFC Account \\nor”, shall be omitted. \\n \\n (P.R. Gopala Rao) \\nExecutive Director \\n \\nPublished in the Official Gazette of Government \\nof India - Extraordinary - Part-II, Section 3, \\nSub-Section (i) dated 25. 08.2000 - G.S.R.No.674(E)'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Relationships"
      ],
      "metadata": {
        "id": "Oqlh0Gxg-u5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding Notification Node"
      ],
      "metadata": {
        "id": "Q73rJXDXJapk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = cypher = \"\"\"\n",
        "    MATCH (c:Chunk)\n",
        "    WITH c\n",
        "    RETURN c { .title, .date, .source } as notifyMeta\n",
        "\"\"\"\n",
        "\n",
        "notification_metadata_list = kg.query(query)"
      ],
      "metadata": {
        "id": "iVHGyLweCv2k"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notification_metadata_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUzaXy5XHSgk",
        "outputId": "8a3b0ae0-7c57-4875-dd58-7b38a8665a21"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'notifyMeta': {'title': 'StCBs/DCCBs - KYC Norms/AML Standards/Combating Financing of Terrorism/Obligation of Banks under PMLA, 2002',\n",
              "  'source': 'https://rbidocs.rbi.org.in/rdocs/notification/PDFs/RFBC89D250610.pdf',\n",
              "  'date': 'June 25, 2010'}}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_notification_constraint_query = \"\"\"\n",
        "CREATE CONSTRAINT unique_notification IF NOT EXISTS\n",
        "    FOR (n:Notification) REQUIRE n.id IS UNIQUE\n",
        "\"\"\"\n",
        "\n",
        "kg.query(distinct_notification_constraint_query)\n",
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "id": "elMKdXeyIzTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cypher = \"\"\"\n",
        "    MERGE (n:Notification {title: $notificationMetadata.title })\n",
        "      ON CREATE\n",
        "        SET n.date = $notificationMetadata.date\n",
        "        SET n.source = $notificationMetadata.source\n",
        "        SET n.id = $id\n",
        "\"\"\"\n",
        "\n",
        "i = 1\n",
        "for notification_metadata in notification_metadata_list[i-1:]:\n",
        "    if notification_metadata['notifyMeta']['title'] is None:\n",
        "        notification_metadata['notifyMeta']['title'] = ''\n",
        "    id = f\"{notification_metadata['notifyMeta']['title']}-{notification_metadata['notifyMeta']['date']}-{notification_metadata['notifyMeta']['source']}\"\n",
        "    kg.query(cypher,\n",
        "             params={'notificationMetadata': notification_metadata['notifyMeta'],\n",
        "                     'id': id})\n",
        "\n",
        "    if i%1000 == 0:\n",
        "        print(f\"{i} Notification Nodes created\")\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "zEGu90dIFkWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notitfication_nodes = kg.query(\"\"\"\n",
        "    MATCH (n:Notification)\n",
        "    RETURN n\"\"\")"
      ],
      "metadata": {
        "id": "XQ73gWuEHE2f"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(notitfication_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usj8xMoipxa_",
        "outputId": "6039ae5e-99ed-4eda-e10c-cf63bd9956a5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4434"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notitfication_nodes[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUWQ5HUpz5Y",
        "outputId": "37ffb2c6-8176-4b1f-c897-731f7df80861"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n': {'date': '',\n",
              "  'source': 'https://rbidocs.rbi.org.in/rdocs/notification/PDFs/60ME300611F.pdf',\n",
              "  'id': 'Master Circular on Rupee / Foreign Currency Export Credit & Customer Service To Exporters--https://rbidocs.rbi.org.in/rdocs/notification/PDFs/60ME300611F.pdf',\n",
              "  'title': 'Master Circular on Rupee / Foreign Currency Export Credit & Customer Service To Exporters'}}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining Chunks"
      ],
      "metadata": {
        "id": "GT-FTIcGg_h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cypher = \"\"\"\n",
        "  MATCH (from_same_section:Chunk)\n",
        "  WHERE from_same_section.title = $title\n",
        "    AND from_same_section.source = $source\n",
        "  WITH from_same_section\n",
        "    ORDER BY from_same_section.chunkSeqId ASC\n",
        "  WITH collect(from_same_section) as chunk_list\n",
        "    CALL apoc.nodes.link(\n",
        "        chunk_list,\n",
        "        \"NEXT\",\n",
        "        {avoidDuplicates: true}\n",
        "    )\n",
        "  RETURN size(chunk_list)\n",
        "\"\"\"\n",
        "\n",
        "i = 1\n",
        "for notification_node in notitfication_nodes[i-1:]:\n",
        "    kg.query(cypher, params={'title': notification_node['n']['title'],\n",
        "                             'source': notification_node['n']['source']})\n",
        "    if i %1000 == 0:\n",
        "        print(f'Added relations for {i} notifications')\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MwcjqvJo6n_",
        "outputId": "375e0561-0815-4177-90e8-3b860cb3b221"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added relations for 1000 notifications\n",
            "Added relations for 2000 notifications\n",
            "Added relations for 3000 notifications\n",
            "Added relations for 4000 notifications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (n)-[r]-()\n",
        "    RETURN count(r)\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zugwvufuBRi",
        "outputId": "ee470c5d-81e4-42b2-9c3e-f1d3eb02c1ef"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'count(r)': 54922}]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relation from Notification to Chunk"
      ],
      "metadata": {
        "id": "4-li5Yh5hHWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cypher = \"\"\"\n",
        "  MATCH (c:Chunk), (n:Notification)\n",
        "    WHERE c.title = n.title\n",
        "        AND c.source = n.source\n",
        "  MERGE (c)-[newRelationship:PART_OF]->(n)\n",
        "  RETURN count(newRelationship)\n",
        "\"\"\"\n",
        "\n",
        "kg.query(cypher)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5VPVvGoZHmC",
        "outputId": "c71f76df-a60e-4f68-9bbe-391eceb47e7e"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'count(newRelationship)': 31895}]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(kg.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4Lxv2jNhesa",
        "outputId": "fa1f584e-b089-460f-ca3e-da2dd781ed6e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties are the following:\n",
            "Chunk {chunkId: STRING, title: STRING, date: STRING, source: STRING, chunkSeqId: INTEGER, text: STRING, textEmbedding: LIST},Notification {title: STRING, date: STRING, source: STRING, id: STRING}\n",
            "Relationship properties are the following:\n",
            "\n",
            "The relationships are the following:\n",
            "(:Chunk)-[:NEXT]->(:Chunk),(:Chunk)-[:PART_OF]->(:Notification)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain RAG Workflow"
      ],
      "metadata": {
        "id": "izHuqCTUv83B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrieval_query_window = \"\"\"\n",
        "MATCH window=\n",
        "    (:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
        "WITH node, score, window as longestWindow\n",
        "  ORDER BY length(window) DESC LIMIT 3\n",
        "WITH nodes(longestWindow) as chunkList, node, score\n",
        "  UNWIND chunkList as chunkRows\n",
        "WITH collect(chunkRows.text) as textList, node, score\n",
        "RETURN apoc.text.join(textList, \" \\n \") as text,\n",
        "    score,\n",
        "    node {.title, .date, .source} AS metadata\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "18SPC_HOdhgi"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store_window = Neo4jVector.from_existing_index(\n",
        "    embedding=CustomTensorflowHubEmbeddings(),\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    database=NEO4J_DB,\n",
        "    index_name=VECTOR_INDEX_NAME,\n",
        "    text_node_property=VECTOR_SOURCE_PROPERTY,\n",
        "    retrieval_query=retrieval_query_window,\n",
        ")\n",
        "\n",
        "# Create a retriever from the vector store\n",
        "retriever_window = vector_store_window.as_retriever()\n",
        "\n",
        "# Create a chatbot Question & Answer chain from the retriever\n",
        "chain_window = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever_window\n",
        ")"
      ],
      "metadata": {
        "id": "MLHSiHAFeOyu"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettychain(question: str) -> str:\n",
        "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
        "    response = chain_window({\"question\": question},\n",
        "        return_only_outputs=True,)\n",
        "    print(textwrap.fill(response['answer'], 60))"
      ],
      "metadata": {
        "id": "mMiEOcX-ekxR"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettychain(\"What were the major policies by RBI in 2000?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pMcSWatfQSe",
        "outputId": "97b8c4af-9608-47ec-fa4f-1bd263b8aec5"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The major policies by RBI in 2000 included the empowerment\n",
            "to compound contraventions relating to Section 7, 8, and 9\n",
            "of FEMA 1999. Additionally, RBI was empowered to compound\n",
            "all contraventions of FEMA 1999 except Section 3(a) with a\n",
            "view to providing comfort to individuals and the corporate\n",
            "community by minimizing transaction costs while taking a\n",
            "severe view of willful, malafide, and fraudulent\n",
            "transactions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pnM4029hlGQ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sc1TqRNoX1LI",
        "6TBXBU-KYFM6",
        "-1aMVsKxjnKY",
        "A6YIL18qjwBK",
        "Oqlh0Gxg-u5u",
        "GT-FTIcGg_h2",
        "4-li5Yh5hHWr"
      ],
      "authorship_tag": "ABX9TyP8uJRuIbVP8m33VVvmIEtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}